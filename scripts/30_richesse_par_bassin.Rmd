---
title: "Richesse par bassin"
author: "Pascal Irz"
date: "`r format(Sys.time(), 'Le %d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Chargement des packages

```{r}
library(aspe)
library(tod)
library(tidyverse)
```

# Principe

Pour calculer les richesses par bassin au fil du temps, on doit procéder par étapes :

- obtention du découpage des bassins, à l'échelle appropriée
- positionner les stations pour les affecter aux bassins 
- Calculer la richesse à chaque pêche
- agréger les pêches par année et bassin

# Découpage géographique en bassins

## Téléchargement de la couche des bassins

Le découpage des bassins au sens de la DCE est téléchargeable depuis [data.gouv.fr](https://www.data.gouv.fr/fr/datasets/bassins-dce/), au format GeoJSON ou [shapefile](https://www.data.gouv.fr/fr/datasets/r/7c3a45a7-518a-4415-80aa-c59e427592c5).

Un découpage plus fin est disponible sur la page [Zones hydrographiques - Métropole 2016 - BD Carthage](https://geo.data.gouv.fr/fr/datasets/f467f445570db14819bdb0058d4038f44f54b77f) du portail [geo.data.gouv.fr](https://geo.data.gouv.fr) et télécharger le shapefile à [cette URL](Zones hydrographiques - Métropole 2016 - BD Carthage). La fonction `sie_carthage_bassins_tod()` du package {tod} permettent d'enchaîner le téléchargement, la décompression et la lecture de la couche shapefile proposée. Par défaut l'archive zip et les fichiers décompressés sont stockés dans un sous-répertoire `"raw_data"` qui est créé s'il ne pré-existe pas. 

```{r, eval = FALSE}
bv <- tod::sie_carthage_bassins_tod(repertoire = "raw_data")
```

```{r, echo = FALSE}
load(file = "../processed_data/bv.RData")
```

La taille de l'objet créé est importante car le niveau de découpage est fin (`r nrow(bv)` polygones) et le tracé est précis.

```{r}
object.size(bv) %>% format(units = "auto")
```

Si l'on veut sauvegarder les bassins :

```{r, eval = FALSE}
save(bv, file = "processed_data/bv.RData")
```

## Simplification de l'objet

Pour des besoins plus "macro" et pour que chaque entité géographique comprenne plusieurs stations d'échantillonnage, on peut regrouper les entités.

```{r}
bv_simp <- bv %>% 
  group_by(CdSecteurH, LbSecteurH) %>% 
    summarise()
```


Ensuite, pour la plupart des usages on peut simplifier la géométrie des bassins. La fonction `ms_simplify()` du package `rmapshaper` est préférable à `st_simplify()` du package `sf` car elle conserve la topologie (gestion des limites communes entre polygones pour éviter de créer des interstices ou des chevauchements).

```{r}
bv_simp <- rmapshaper::ms_simplify(bv_simp, keep = 0.01)
```

Les contours des bassins ainsi simplifiés pèsent `r object.size(bv_simp) %>% format(units = "auto")`, ce qui est beaucoup plus raisonnable. On peut les visualiser avec le package `ggplot2`.

```{r}
ggplot(bv_simp) + geom_sf()
```


# Inventaires piscicoles

## Chargement des données

Les données ont été parsées depuis un dump de la base Aspe (cf. [ce tuto](https://rpubs.com/kamoke/713407)).

```{r, eval = FALSE}

load(file = "processed_data/toutes_tables_aspe_sauf_mei.RData")
```

```{r, eval = TRUE, echo = FALSE}

load(file = "../processed_data/toutes_tables_aspe_sauf_mei.RData")
```

## Assemblage et filtrage des données

Le principe pour utiliser les tables de la base sql d'origine est de constituer un `dataframe` "passerelle" qui relie les tables d'origine par les identifiants de leurs objets (stations, points, opérations, lots, etc.). On peut ensuite compléter cette ossature par des jointures sur les champs contenant les identifiants. La démarche se retrouve systématiquement dans les traitements donc elle n'a été détaillée qu'une fois dans [ce tuto](https://rpubs.com/kamoke/713491).

```{r}
passerelle <- mef_creer_passerelle()
```

On ne conserve que les pêches complètes à pied.

```{r}
data <- passerelle   %>% 
  left_join(y = operation_description_peche %>%
                      select(ope_id = odp_ope_id, mop_id = odp_mop_id)) %>% 
  left_join(y = ref_moyen_prospection %>%
                      select(mop_id, mop_libelle)) %>% 
  filter(mop_libelle == 'A pied') %>% 
  select(-mop_id, -mop_libelle) %>% 
  left_join(y = operation %>%
                    select(ope_id, pro_id = ope_pro_id)) %>% 
  filter(pro_id == 1) %>% #  pêches complètes : pro_id == 1
  select(-pro_id)
```

## Ajout des données sur les captures

```{r}
data <- data %>% 
  left_join(y = lot_poissons %>%
                    select(lop_id, esp_id = lop_esp_id, lop_effectif)) %>%
  left_join(y = ref_espece %>%
                    select(esp_id, esp_code_alternatif)) %>% 
  select(-esp_id)
```

## Agrégation pour simplifier le tableau

```{r}
data <- data %>% 
  group_by(sta_id, pop_id, ope_id, esp_code_alternatif) %>% 
    summarise(effectif = sum(lop_effectif, na.rm = TRUE)) %>% 
  ungroup()
  
```

## Sélection des espèces

Un tableau a été constitué pour caractériser sommairement les espèces de poissons référencées dans la base Aspe quant à leur statut (introduite ?) ou à leur habitat primaire. Il est accessible directement depuis le package {aspe} :

```{r}
data(traits_poissons)
DT::datatable(traits_poissons,
              rownames = FALSE,
              options = list(
                columnDefs = list(list(className = 'dt-center', targets="_all"))
            ))
```

Restriction du jeu de données aux espèces de poissons (suppression des écrevisses, des hybrides ou des individus pour lesquels la détermination à l'espèce n'a pas été possible) qui ne sont ni marines ni lacustres.

```{r}
mes_especes <- traits_poissons %>% 
  filter(Marin == FALSE & Lacustre == FALSE) %>% 
  pull(esp_code_alternatif)

data <- data %>% 
  filter(esp_code_alternatif %in% mes_especes)
```


# Ajout des données sur les points de prélèvements

Cette étape est nécessaire pour avoir les coordonnées et donc permettre de relier les points aux bassins.

Comme il y a dans les données plusieurs systèmes de coordonnées (CRS) qui cohabitent, il va falloir non seulement récupérer les coordonnées, mais aussi les homogénéiser en les reprojetant dans un même CRS (ici le WGS84 du GPS).

```{r}
data <- data %>% 
  left_join(y = point_prelevement %>% 
                  select(pop_id, pop_coordonnees_x, pop_coordonnees_y, typ_id = pop_typ_id))
```

# Spatialisation

## Gestion des CRS

### Ajout des codes EPSG

Il apparaît que dans le référentiel des systèmes de coordonnées, pour le Lambert II étendu, le code EPSG (27572) est manquant. Il faut donc compléter la table `ref_type_projection`.

```{r}
ref_type_projection <- ref_type_projection %>%
  mutate(typ_code_epsg = ifelse((is.na(typ_code_epsg) & typ_libelle_sandre == "Lambert II Etendu"),
                                 yes = 27572,
                                 no = typ_code_epsg))
```

On peut alors faire la jointure pour ajouter au tableau `data` le code EPSG du CRS.

```{r}
data <- data %>% 
  left_join(y = ref_type_projection %>%
                  select(typ_id, typ_code_epsg))
```

### Calcul des coordonnées

On calcule les coordonnées en WGS84 avec la fonction `geo_convertir_coords_df()`.

```{r}
coords_wgs84 <- data %>% 
  geo_convertir_coords_df(var_x = "pop_coordonnees_x",
                          var_y = "pop_coordonnees_y",
                          var_crs_initial = "typ_code_epsg",
                          crs_sortie = 4326) %>%
  rename(x_wgs84 = X, y_wgs84 = Y)
```

## Création d'objects géographiques

On crée des objets "points" de classe `sf`.  

```{r}
data_geo <- data %>%
  bind_cols(coords_wgs84) %>%
  select(-(pop_coordonnees_x:typ_code_epsg)) %>% 
  sf::st_as_sf(coords = c("x_wgs84", "y_wgs84"), crs = 4326)
```

Pour effectuer la jointure entre les bassins et les stations, il faut que les deux soient dans un même système de coordonnées (CRS) donc on reprojette les bassins (qui sont en Lambert 93) en WGS84 dont l'indentifiant est `4326`.

```{r}
bv <- bv %>% 
  sf::st_transform(crs = 4326)
```

## Croisement géographique

On attribue à chaque donnée (en fait à chaque lot de poissons) le bassin d'appartenance de son point, puis on restreint à la France continentale. 

```{r}
data_geo <- data_geo %>% 
  sf::st_join(bv) %>% 
  filter(!(CdSecteurH %in% c('Y7', 'Y8', 'Y9'))) %>% #• suppression Corse
  filter(!is.na(gid)) # suppression des points sans bv

```

# Richesse par bassin

## Agrégation par bassin

On agrège, toutes années confondues.

```{r}
richesse_par_bv <- data_geo %>% 
  group_by(CdSecteurH, LbSecteurH) %>% 
    summarise(richesse = n_distinct(esp_code_alternatif),
              nb_ope = n_distinct(ope_id)) %>% 
  ungroup() %>%    
  sf::st_drop_geometry() %>% 
  select(CdSecteurH, richesse, nb_ope) %>% 
  right_join(y = bv_simp) %>% 
  sf::st_as_sf() %>% 
  filter(!is.na(richesse))
```

```{r}
pal <- RColorBrewer::brewer.pal(20, "OrRd")

map_data <- richesse_par_bv %>% 
                   rename("Secteur Hydro" = LbSecteurH,
                          Richesse = richesse,
                          "Nombre de pêches" = nb_ope)

mapview::mapview(map_data,
                 zcol = "Richesse",
                 col.regions = pal,
                 layer.name = "Richesse",
                 popup = leafpop::popupTable(prov,
                                             zcol = c("Secteur Hydro", "Richesse", "Nombre de pêches"),
                                             feature.id = FALSE,
                                             row.numbers = FALSE))
```

## Lien entre richesse et effort de prospection ?

Pour savoir s'il y a un effet de l'effort de prospection sur la richesse détectée, on peut représenter la richesse en fonction du nombre d'opérations. Un point représente un bassin.

```{r}
ggplot(data = richesse_par_bv,
       aes(x = nb_ope, y = richesse)) +
  geom_point() +
  scale_x_log10() +
  geom_smooth(method = lm, se = FALSE)
```

>Là on est fixé ! Ca interroge sur la représentation cartographique ...

# Approche temporelle

## Richesse moyenne par opération

On calcule d'abord la richesse par opération.

```{r}
richesse_par_ope <- data %>% 
  left_join(y = operation %>% select(ope_id, ope_date)) %>% 
  mutate(ope_date = as.character(ope_date),
         ope_date = lubridate::ymd_hms(ope_date),
         annee = lubridate::year(ope_date)) %>% 
  group_by(pop_id, ope_id, annee) %>% 
    summarise(richesse_ope = n_distinct(esp_code_alternatif))
```

Puis on moyenne par année.

```{r}
richesse_moy_point_an <- richesse_par_ope %>% 
  group_by(annee) %>% 
    summarise(richesse_moy = mean(richesse_ope),
              richesse_et = sd(richesse_ope),
              richesse_ic = sd(richesse_ope) / sqrt(n()))
```

Les barres représentent l'intervalle de confiance sur la moyenne.

```{r}
ggplot(data = richesse_moy_point_an,
       aes(x = annee, y = richesse_moy, ymax = richesse_moy + richesse_ic, ymin = richesse_moy - richesse_ic)) +
  geom_pointrange() +
  scale_y_continuous(limits = c(0, NA))
```


